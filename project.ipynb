{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from collections.abc import Iterable\n",
    "from datasets import load_dataset, list_datasets\n",
    "\n",
    "# Model and tokenizer from ðŸ¤— Transformers\n",
    "from transformers import AutoModelForSequenceClassification, \\\n",
    "    BertForSequenceClassification, BertTokenizerFast, AutoModel, AutoTokenizer\n",
    "\n",
    "# Code you will write for this assignment\n",
    "from train_model import init_model, preprocess_dataset, init_trainer\n",
    "from test_model import init_tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset hate_speech_offensive (/Users/jiayuansong/.cache/huggingface/datasets/hate_speech_offensive/default/1.0.0/5f5dfc7b42b5c650fe30a8c49df90b7dbb9c7a4b3fe43ae2e66fabfea35113f5)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.04it/s]\n",
      "Loading cached split indices for dataset at /Users/jiayuansong/.cache/huggingface/datasets/hate_speech_offensive/default/1.0.0/5f5dfc7b42b5c650fe30a8c49df90b7dbb9c7a4b3fe43ae2e66fabfea35113f5/cache-e8bc8b2108a4c2d9.arrow and /Users/jiayuansong/.cache/huggingface/datasets/hate_speech_offensive/default/1.0.0/5f5dfc7b42b5c650fe30a8c49df90b7dbb9c7a4b3fe43ae2e66fabfea35113f5/cache-39dae8e28af0c6f7.arrow\n",
      "Loading cached split indices for dataset at /Users/jiayuansong/.cache/huggingface/datasets/hate_speech_offensive/default/1.0.0/5f5dfc7b42b5c650fe30a8c49df90b7dbb9c7a4b3fe43ae2e66fabfea35113f5/cache-1abefe43e27c4edd.arrow and /Users/jiayuansong/.cache/huggingface/datasets/hate_speech_offensive/default/1.0.0/5f5dfc7b42b5c650fe30a8c49df90b7dbb9c7a4b3fe43ae2e66fabfea35113f5/cache-594532248aff7dc6.arrow\n"
     ]
    }
   ],
   "source": [
    "hate_speech = load_dataset(\"hate_speech_offensive\")\n",
    "split = hate_speech[\"train\"].train_test_split(.2, seed=3463)\n",
    "hate_speech[\"train\"] = split[\"train\"]\n",
    "hate_speech[\"test\"] = split[\"test\"]\n",
    "\n",
    "split = hate_speech[\"train\"].train_test_split(.2, seed=3463)\n",
    "hate_speech[\"train\"] = split[\"train\"]\n",
    "hate_speech[\"val\"] = split[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "emoji is not installed, thus not converting emoticons or emojis into text. Install emoji: pip3 install emoji==0.6.0\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/jiayuansong/.cache/huggingface/datasets/hate_speech_offensive/default/1.0.0/5f5dfc7b42b5c650fe30a8c49df90b7dbb9c7a4b3fe43ae2e66fabfea35113f5/cache-c5ff1d17dbe917a1.arrow\n",
      "Loading cached processed dataset at /Users/jiayuansong/.cache/huggingface/datasets/hate_speech_offensive/default/1.0.0/5f5dfc7b42b5c650fe30a8c49df90b7dbb9c7a4b3fe43ae2e66fabfea35113f5/cache-84813d364895bf57.arrow\n",
      "Loading cached processed dataset at /Users/jiayuansong/.cache/huggingface/datasets/hate_speech_offensive/default/1.0.0/5f5dfc7b42b5c650fe30a8c49df90b7dbb9c7a4b3fe43ae2e66fabfea35113f5/cache-9bfc15eafb4812d9.arrow\n",
      "Loading cached processed dataset at /Users/jiayuansong/.cache/huggingface/datasets/hate_speech_offensive/default/1.0.0/5f5dfc7b42b5c650fe30a8c49df90b7dbb9c7a4b3fe43ae2e66fabfea35113f5/cache-7b3c62595437f215.arrow\n",
      "Loading cached processed dataset at /Users/jiayuansong/.cache/huggingface/datasets/hate_speech_offensive/default/1.0.0/5f5dfc7b42b5c650fe30a8c49df90b7dbb9c7a4b3fe43ae2e66fabfea35113f5/cache-8c91a7689c5b7841.arrow\n",
      "Loading cached processed dataset at /Users/jiayuansong/.cache/huggingface/datasets/hate_speech_offensive/default/1.0.0/5f5dfc7b42b5c650fe30a8c49df90b7dbb9c7a4b3fe43ae2e66fabfea35113f5/cache-63b6b8be84d00dfa.arrow\n",
      "Loading cached processed dataset at /Users/jiayuansong/.cache/huggingface/datasets/hate_speech_offensive/default/1.0.0/5f5dfc7b42b5c650fe30a8c49df90b7dbb9c7a4b3fe43ae2e66fabfea35113f5/cache-f56a88c0063839d4.arrow\n",
      "Loading cached processed dataset at /Users/jiayuansong/.cache/huggingface/datasets/hate_speech_offensive/default/1.0.0/5f5dfc7b42b5c650fe30a8c49df90b7dbb9c7a4b3fe43ae2e66fabfea35113f5/cache-9f37dee17aff0745.arrow\n",
      "                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count:\n",
      "<class 'list'>\n",
      "[6, 3]\n",
      "\n",
      "hate_speech_count:\n",
      "<class 'list'>\n",
      "[2, 0]\n",
      "\n",
      "offensive_language_count:\n",
      "<class 'list'>\n",
      "[4, 3]\n",
      "\n",
      "neither_count:\n",
      "<class 'list'>\n",
      "[0, 0]\n",
      "\n",
      "class:\n",
      "<class 'list'>\n",
      "[1, 1]\n",
      "\n",
      "tweet:\n",
      "<class 'list'>\n",
      "['RT @realist_iLLest: ', 'Almost done with thi']\n",
      "\n",
      "demo_props:\n",
      "<class 'list'>\n",
      "[[0.26882176380724737, 0.36224836621752143, 0.0058887965306269295, 0.36304107344460435], [0.538484164995624, 0.22799105326083585, 0.005798052499449793, 0.22772672924409032]]\n",
      "\n",
      "labels:\n",
      "<class 'list'>\n",
      "[1, 1]\n",
      "\n",
      "input_ids:\n",
      "<class 'list'>\n",
      "[[0, 246, 5238, 3320, 10987, 524, 510, 7310, 2110, 22, 19295, 33123, 1981, 17742, 5238, 44662, 864, 31959, 22, 2443], [0, 4267, 270, 30, 33, 397, 245, 551, 639, 28, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "\n",
      "token_type_ids:\n",
      "<class 'list'>\n",
      "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "\n",
      "attention_mask:\n",
      "<class 'list'>\n",
      "[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "hate_speech[\"train\"] = preprocess_dataset(hate_speech[\"train\"], tokenizer)\n",
    "hate_speech[\"val\"] = preprocess_dataset(hate_speech[\"val\"], tokenizer)\n",
    "hate_speech[\"test\"] = preprocess_dataset(hate_speech[\"test\"], tokenizer)\n",
    "\n",
    "# Visualize the preprocessed dataset\n",
    "for k, v in hate_speech[\"val\"][:2].items(): \n",
    "    print(\"{}:\\n{}\\n{}\\n\".format(k, type(v),\n",
    "                                 [item[:20] if isinstance(item, Iterable) else \n",
    "                                 item for item in v[:5]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1531,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = hate_speech['test'] \n",
    "props = np.array(data['demo_props']) \n",
    "aae_idx = np.where(props[:,0] >= 0.6)\n",
    "aae_idx[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle  \n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "\n",
    "class Evaluation:\n",
    "    \n",
    "    def __init__(self, file: str, data: Dataset, threshold=0.6): \n",
    "        ''' \n",
    "        Parameters: \n",
    "            \n",
    "        '''\n",
    "        self.predictions = self.parse_result(file)  \n",
    "        self.labels = self.parse_label(data)\n",
    "        self._aae_idx, self._white_idx = self.parse_demo(data, threshold)\n",
    "        assert len(self.labels) == len(self.predictions) \n",
    "\n",
    "    @ staticmethod \n",
    "    def parse_result(file): \n",
    "        with open(file, 'rb') as f:\n",
    "            obj = pickle.load(f)\n",
    "        return obj.predictions.argmax(axis=1) \n",
    "    \n",
    "    @ staticmethod \n",
    "    def parse_demo(data, threshold): \n",
    "        props = np.array(data['demo_props']) \n",
    "        aae = np.where(props[:,0] >= threshold)[0]\n",
    "        # white = np.where(props[:,-1] >= threshold)[0] \n",
    "        white = np.where(props[:,0] < threshold)[0] # non-aae \n",
    "        return aae, white \n",
    "                \n",
    "    @ staticmethod \n",
    "    def parse_label(data):\n",
    "        return np.array(data['labels']) \n",
    "    \n",
    "    def get_EOD(self): \n",
    "        ''' \n",
    "        returns the 'equal opportunity difference' {\n",
    "            between true positive rates of white and aae predictions; \n",
    "            the closer to 0 the better; \n",
    "        } \n",
    "        ''' \n",
    "        \n",
    "        white_tpr = (self.predictions[self._white_pos_true] == 1).sum() / self._white_pos_true.shape[0] \n",
    "        aae_tpr = (self.predictions[self._aae_pos_true] == 1).sum() / self._aae_pos_true.shape[0]\n",
    "        print(white_tpr) \n",
    "        print(aae_tpr)\n",
    "        return white_tpr - aae_tpr \n",
    "\n",
    "    def get_AOD(self):\n",
    "        pass \n",
    "\n",
    "    def get_SPD(self): \n",
    "        '''\n",
    "        returns the 'statistical parity difference' {\n",
    "            between probabilities of toxic white and aae classifications; \n",
    "            the closer to 0 the better;  \n",
    "\n",
    "        }\n",
    "        ''' \n",
    "        return  self._white_pos_true.shape[0]/self._white_idx.shape[0] - self._aae_pos_true.shape[0]/self._aae_idx.shape[0] \n",
    "\n",
    "    def get_DI(self): \n",
    "        '''\n",
    "        returns the 'disparate impact' { \n",
    "            not impacted by annotations; \n",
    "            acceptable between 0.8 and 1.2; \n",
    "        }\n",
    "        '''\n",
    "        di_toxic = (self._aae_pos_true.shape[0]/self._aae_idx.shape[0]) / (self._white_pos_true.shape[0]/self._white_idx.shape[0])\n",
    "        di_nontoxic = (1 - self._aae_pos_true.shape[0]/self._aae_idx.shape[0]) / (1 - self._white_pos_true.shape[0]/self._white_idx.shape[0]) \n",
    "        return (di_toxic, di_nontoxic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = Evaluation.parse_result('test_results.p')  \n",
    "labels = Evaluation.parse_label(hate_speech['test'])\n",
    "_aae_idx, _white_idx = Evaluation.parse_demo(hate_speech['test'], 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_white = predictions[_white_idx] \n",
    "pred_aae = predictions[_aae_idx] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[predictions==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_results.p', 'rb') as f:\n",
    "    obj = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.predictions.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(pred_aae) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval = Evaluation('test_results.p', hate_speech['test'], 0.6) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7914383561643835\n",
      "0.7939086294416243\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.0024702732772408087"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval.get_EOD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.3133510933210728, 0.10645977295162863)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval.get_DI() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.2319942171646887"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval.get_SPD() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('test_results.p', 'rb') as f:\n",
    "    obj = pickle.load(f)\n",
    "predictions = obj.predictions.argmax(axis=1)  \n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[[1,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7435"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "texts = np.array(hate_speech['test']['tweet'])\n",
    "true_labels = np.array(hate_speech['test']['labels'])\n",
    "len(true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7435,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2479,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (7435,) (2479,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m texts[\u001b[43m(\u001b[49m\u001b[43mtrue_labels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred_labels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m]\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (7435,) (2479,) "
     ]
    }
   ],
   "source": [
    "texts[(true_labels == 0) & (pred_labels == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9bece8a4ae55facad4a9f75626b6157080e84d45cc8667e9d052a17ecde009f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
